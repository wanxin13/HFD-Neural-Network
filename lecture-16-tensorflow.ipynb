{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Tensorflow](https://www.tensorflow.org) is an open source library for numerical computation.\n",
    "Tensorflow implements a symbolic math library that is used to build a computation graph.\n",
    "This graph is a representation of the computations we wish to perform.\n",
    "When we write a graph with TensorFlow it is like writing an equation in paper, there are no actual computations occurring.\n",
    "TensorFlow uses the graph to automatically compute the derivatives required for stochastic gradient descent.\n",
    "When it is time to actually perform the computations, TensorFlow uses algorithms in C and C++ for it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Install\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow can be installed with `pip`.\n",
    "After activating your environment in the terminal, run:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `numpy` is available for Python and can be imported with:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the Tensorflow functionality can now be accessed via the object `tensorflow`.\n",
    "\n",
    "You will often see the following command being used:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which makes the `tensorflow` functionality available via `tf`.\n",
    "This is often used because it requires less typing to use numpy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Building the Graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import TensorFlow:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A default graph which is empty is automatically created when we first import TensorFlow. We can access this default graph via:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see what operations are attached to it (none in this case) with:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that when we add operations to this graph (think about the nodes and connections in a neural network graph) nothing is actually being computed, we are just creating the structure of the function.\n",
    "\n",
    "The simplest operation we can add is a constant:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant(3.1415)             # creates a constant in the default graph\n",
    "graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that by calling `tf.constant`, TensorFlow automatically adds a constant to the default graph, which we can see was added with the `get_operations` method.\n",
    "We did not need to explicitly tell TensorFlow which graph to alter.\n",
    "We can specify which graph to alter, but usually the default graph will suffice.\n",
    "\n",
    "Each operation in TensorFlow takes an input and generates an output.\n",
    "Think about the signal $s_k$ in the neural network graph. It takes as input the features $x_1,\\dots,x_n$, and outputs the value of the signal $s_k$.\n",
    "A constant has no inputs, but only an output.\n",
    "We can see those values via:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant = graph.get_operations()[0]\n",
    "print(f'Constant: number of inputs = {len(constant.inputs)}')\n",
    "print(f'Constant: number of outputs = {len(constant.outputs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output has a special type:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(constant.outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type is `tf.Tensor`, which can represent data in a scalar, vector, matrix or a multidimensional array.\n",
    "The `shape` is `()` which implies this tensor represents a constant.\n",
    "\n",
    "All tensors are outputs of some operation in the graph.\n",
    "In this case, the tensor above is the output of a \"constant operation\".\n",
    "\n",
    "Let's add in another constant:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant(2.5)\n",
    "another_constant = graph.get_operations()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are two operations in the graph.\n",
    "Notice each has a name, \"Const\" and \"Const<sub>1</sub>\".\n",
    "Also observe the types are `tf.Operation`.\n",
    "\n",
    "Let's create a new operation that will sum up the two constants.\n",
    "First, we need to give names to the outputs of the two constants, so that the addition knows what to add:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_constant_tensor = constant.outputs[0]\n",
    "second_constant_tensor = another_constant.outputs[0]\n",
    "print(first_constant_tensor, second_constant_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The naming of the tensors follows `operation_name:output_number`.\n",
    "So \"Const:0\" means the 0th output (first output) coming out of the operation \"Const\".\n",
    "\n",
    "We can combine these outputs:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "addition_tensor = tf.add(first_constant_tensor, second_constant_tensor)\n",
    "graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important, when we create a new operation and assign it to a variable, like `sum_tensor` above, the variable gets the output of the operation, not the operation itself. That is, `sum_tensor` is already the output of `tf.add`.\n",
    "\n",
    "We can verify that the addition operation takes two inputs and generates one output:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "addition_operation = graph.get_operations()[2]\n",
    "print(f'Inputs: {len(addition_operation.inputs)}\\n'\n",
    "      f'Outputs: {len(addition_operation.outputs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Running the Computations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now run this computation.\n",
    "To do so, we need to create a `Session` object.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()          # uses the default graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Session object stores a reference to the graph we just constructed, determines how much memory it will need and sets up some other configurations.\n",
    "\n",
    "We can see that the default graph is indeed being used via:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.graph == graph          # true, same graph\n",
    "session.graph is graph          # they are the same object!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a method `Session.run` which sends the graph to the computation engine to be executed.\n",
    "The method takes as input the tensor you want to compute.\n",
    "If we want to compute the tensor of the addition, we would run:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(addition_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass a list of tensors to compute.\n",
    "This is more efficient, because each time we call the `Session.run` method all computations are performed again.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run([first_constant_tensor, second_constant_tensor, addition_tensor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we are done with the computations, we can close the session to free resources:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Placeholders\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph we built uses the same two constant values as inputs to the addition operation.\n",
    "Let's modify it so that it can take variable inputs.\n",
    "In tensorflow variables are created with `tf.placeholder`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command above adds a placeholder to the default graph.\n",
    "It takes as input the type of the variable, in this case it is a 32 bytes float.\n",
    "Other possible types are: `tf.int32` and `tf.bool`.\n",
    "A complete list is available [here](https://www.tensorflow.org/api_docs/python/tf/DType).\n",
    "\n",
    "Let's add a second placeholder and create a new addition operation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "flexible_addition = tf.add(x, y)\n",
    "print(graph.get_operations())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now open a `Session` and `Session.run` the `flexible_addition` tensor to get its value.\n",
    "However, now we need to pass an additional input, the actual values we want for `x` and `y` at the time of computation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(flexible_addition,\n",
    "            feed_dict={x: 10.0, y:25.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also give multiple inputs to be evaluated:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.run(flexible_addition, feed_dict={\n",
    "    x: [1.0, 2.0, -10.0],\n",
    "    y: [-1.0, 3.0, 20.0]\n",
    "})\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fetch the value of a tensor multiple times, and each time we can give a new value to the placeholder.\n",
    "If we give it a list of values, then it will use that list as an input.\n",
    "\n",
    "Notice that the tensor we created for addition uses the `tf.add` method, not the Python `+` method.\n",
    "In Python, using `+` to \"add\" two lists actually contatenate them:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([0, 1] + [2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tf.add` implements vector addition (actually tensor addition).\n",
    "\n",
    "It is possible to add multiple operations at once:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_from_origin = tf.sqrt(tf.add(tf.pow(x, 2), tf.pow(y, 2)))\n",
    "graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the value of this tensor for multiple inputs via:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(distance_from_origin, feed_dict={\n",
    "    x: [0.0, 5.0, 10.0],\n",
    "    y: [-1.0 , 3.0, 0.0]\n",
    "})\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This operation of opening a `Session` performing a computation and then closing it is recurrent in programming in general.\n",
    "Python has a special syntax to reduce the number of lines it takes to write the above:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(distance_from_origin, feed_dict={\n",
    "      x: [0.0, 5.0, 10.0],\n",
    "      y: [-1.0 , 3.0, 0.0]\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `with` takes care of opening the `Session` and then closing it when the block of indented code finished running.\n",
    "\n",
    "We can clear the default graph with:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "graph = tf.get_default_graph()\n",
    "graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables are just like placeholders in the sense that they are filled with different values. Unlike placeholders, however, the value of variables are persistent across calls to `session.run`.\n",
    "TensorFlow uses `tf.Variable` to hold the value of parameters over which we optimize the value of some loss function.\n",
    "\n",
    "The `tf.Variable` constructor takes one input as argument. This input defines the type of the variable, like an integer, floar or even a list.\n",
    "Let's create a new variable:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph.get_operations())\n",
    "x = tf.Variable(33)             # variable type is integer\n",
    "print(graph.get_operations())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that 4 new operations were added to the graph. These operations provide ways to assign value to the variable and to read the value from it.\n",
    "\n",
    "If we try to run a session to get the value of `x` we will get an error:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error says we are \"Attempting to use uninitialized value Variable<sub>1</sub>:0\".\n",
    "The value `33` is used to determine the type of the variable, but is not automatically set as the default value of the variable.\n",
    "Thus, the variable does not have a value when we try `Session.run` on it.\n",
    "To assign the number `33` as the default value of `x` we need to initialize it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    print(session.run(x.initializer), session.run(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first call to the initializer sets the default value of the Variable.\n",
    "All variables have an `initialize` method to initialize its default value.\n",
    "Now, because `x` is a Variable, when we call `session.run` again its value is still `33`.\n",
    "This contrasts to placeholders.\n",
    "A placeholder needs its value to be set every time we call `session.run`.\n",
    "We will use placeholders as the input of the neural network.\n",
    "\n",
    "There is a helper function that initializes all of the variables to their default values at once:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_all = tf.global_variables_initializer()\n",
    "with tf.Session() as session:\n",
    "    session.run(initialize_all)\n",
    "    session.run(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `tf.global_variables_initializer` initializes all of the variables in the graph.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Computing Gradients\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main reasons for using TensorFlow is the ability to automatically compute the gradient of a loss function defined on top of a graph.\n",
    "\n",
    "To do so, we use the method `tf.gradients`.\n",
    "This method takes two arguments:\n",
    "\n",
    "1.  `ys`: a tensor or a list of tensors we would like to derivate\n",
    "2.  `xs`: a tensor or a list of tensors to derivate with respect to\n",
    "\n",
    "The `tf.gradients` method follows the graph starting at `ys` to compute the derivatives.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "graph = tf.get_default_graph()\n",
    "x = tf.Variable(0.0)            # float variable\n",
    "y = tf.pow(x, 2)\n",
    "gradient = tf.gradients(y, x)\n",
    "initializer = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's execute the graph to get the actual value:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(initializer)\n",
    "    session.run(gradient, feed_dict={x:10.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns the derivative of $x^2$ with respect to $x$ evaluated at $x=10$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Optimization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now implement a linear regression using stochastic gradient descent with TensorFlow.\n",
    "\n",
    "Let's generate some fake data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "noise = np.random.normal(size=(1000, 1))\n",
    "x = np.random.normal(size=(1000, 10))\n",
    "beta = np.random.uniform(size=(10, 1))\n",
    "y = x@beta + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's divide the data into training, validation and test sets:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "Data = collections.namedtuple('Data', ['x', 'y'])\n",
    "train = Data(x[:800], y[:800])\n",
    "validate = Data(x[800:900], y[800:900])\n",
    "test = Data(x[900:], y[900:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the training data to estimate the parameters, and the validate data to estimate the out of sample loss as we improve the parameter estimates.\n",
    "Now, let's build the linear model graph:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "graph = tf.get_default_graph()\n",
    "# create a placeholder for the input to the linear function\n",
    "# linear function: y = x*b + constant*b0\n",
    "x_input = tf.placeholder(tf.float32, [None, 10])\n",
    "constant = tf.constant(1.0)     # add a constant to the linear model\n",
    "# create a variable placeholder for the betas\n",
    "b = tf.Variable(tf.ones((10, 1)))\n",
    "b0 = tf.Variable(1.0)        # we created a b0 for the constant\n",
    "# compute the prediction for y\n",
    "y_pred = tf.add(tf.matmul(x_input, b), tf.multiply(constant, b0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The definition of the placeholder `x_input` takes two arguments: the data type (float) and the shape.\n",
    "The shape is `None` lines by 10 columns, and the `None` tells TensorFlow that the number of lines can be anything.\n",
    "\n",
    "If we pass in a vector for `x_input`, then we can obtain the value of the tensor `y_pred`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.global_variables_initializer()\n",
    "with tf.Session() as session:\n",
    "    session.run(initializer)\n",
    "    session.run(y_pred, feed_dict={x_input: np.ones((1, 10))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiples lines are passed to `x_input`, then we get an array of predictions for $y$:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.global_variables_initializer()\n",
    "with tf.Session() as session:\n",
    "    session.run(initializer)\n",
    "    session.run(y_pred, feed_dict={x_input: np.ones((20, 10))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add the loss function to the graph:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_input = tf.placeholder(tf.float32, [None, 1])\n",
    "loss = tf.reduce_mean(tf.pow(tf.subtract(y_input, y_pred), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the mean squared error on the training set:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(initializer)\n",
    "    session.run(loss, feed_dict={\n",
    "        x_input: train.x,\n",
    "        y_input: train.y\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the value of the parameters (betas) we will use stochastic gradient descent.\n",
    "TensorFlow has us covered with the operation `tf.train.GradientDescentOptimizer`.\n",
    "We can use it to directly compute one step of the gradient descent.\n",
    "The gradient descent method takes as input the learning rate, and provides a method called `minimize`.\n",
    "This `minimize` method takes as input a tensor representing the loss function, and it then takes one step on the gradient descent algorithm using the gradient values of the loss function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one_step = tf.train.GradientDescentOptimizer(learning_rate=0.005).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time we fetch the operation above, it takes a step following the gradient descent evaluated on whatever data was passed as input to the model.\n",
    "Because we do not have a lot of data, we can run the gradient descent using the entire training set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "beta_hat, b0_hat, MSE = None, None, None\n",
    "with tf.Session() as session:\n",
    "    session.run(initializer)\n",
    "    for i in range(epochs):\n",
    "        [_, MSE, b0_hat, beta_hat] = session.run(\n",
    "            [train_one_step, loss, b0, b], feed_dict={\n",
    "                x_input: train.x,\n",
    "                y_input: train.y\n",
    "            })\n",
    "        if i % 500 == 0:\n",
    "            MSE_validate = session.run(loss, feed_dict={\n",
    "                x_input: validate.x,\n",
    "                y_input: validate.y\n",
    "            })\n",
    "            print(f'MSE at step {i} = {MSE_validate}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the betas estimated with only part of the sample to the true betas:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{\"True Value\":^20}|{\"Estimated Value\":^20}')\n",
    "for true_value, estimated_value in zip(beta[:,0], beta_hat[:,0]):\n",
    "      print(f'{true_value:^20.4f}|{estimated_value:^20.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate how well this model does on the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = test.x@beta_hat + b0_hat\n",
    "MSE_test_set = np.mean((test.y - y_hat)**2)\n",
    "print(f'MSE on test set = {MSE_test_set}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to implement the stochastic gradient descent, then we would feed a single random data point and then update the weights with the gradient descent on the loss function:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stochastic gradient descent\n",
    "epochs = 5000\n",
    "beta_hat, b0_hat, MSE = None, None, None\n",
    "with tf.Session() as session:\n",
    "    session.run(initializer)\n",
    "    for i in range(epochs):\n",
    "        # feed a few data points to compute the gradient\n",
    "        # of the loss and update the weights\n",
    "        for j in range(len(train.x)/50):\n",
    "            indices = np.random.randint(0, len(test.x), size=50)\n",
    "            _ = session.run(train_one_step, feed_dict={\n",
    "                x_input: train.x[indices, :].reshape(1, 10),\n",
    "                y_input: train.y[indices, :].reshape(1, 1)\n",
    "            })\n",
    "        if i % 500 == 0:\n",
    "            MSE_validate = session.run(loss, feed_dict={\n",
    "                x_input: validate.x,\n",
    "                y_input: validate.y\n",
    "            })\n",
    "            print(f'MSE at step {i} = {MSE_validate}', end='\\r')\n",
    "    [beta_hat, b0_hat] = session.run([b, b0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Neural Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use the same data to estimate a simple neural network.\n",
    "First, reset the default graph:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create the 1st layer of the neural network:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a placeholder for the inputs\n",
    "x_input = tf.placeholder(tf.float32, [None, 10])\n",
    "# create weights and bias for the first layer\n",
    "W1 = tf.Variable(tf.random_normal([10, 5]))\n",
    "B1 = tf.Variable(1.0)\n",
    "# create first signals and apply the non-linear transformation\n",
    "s1 = tf.nn.relu(tf.add(tf.matmul(x_input, W1), B1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a final layer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create weights and bias for the last layer\n",
    "W2 = tf.Variable(tf.random_normal([5, 1]))\n",
    "B2 = tf.Variable(1.0)\n",
    "# generate output of the model\n",
    "y_prediction = tf.add(tf.matmul(s1, W2), B2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the loss function:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_input = tf.placeholder(tf.float32, [None, 1])\n",
    "loss = tf.reduce_mean(tf.squared_difference(y_input, y_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the gradient descent optimizer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one_step = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimize the loss function to estimate the parameters:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20000\n",
    "initializer = tf.global_variables_initializer()\n",
    "with tf.Session() as session:\n",
    "    session.run(initializer)\n",
    "    print(f'\\n\\nSTEP | MSE')\n",
    "    for i in range(epochs):\n",
    "        _ = session.run(train_one_step, feed_dict={\n",
    "            x_input: train.x,\n",
    "            y_input: train.y\n",
    "        })\n",
    "        if i % 500 == 0:\n",
    "            MSE = session.run(loss, feed_dict={\n",
    "                x_input: validate.x,\n",
    "                y_input: validate.y\n",
    "            })\n",
    "            print(f'{i:^5}|{MSE:^4}')\n",
    "    MSE = session.run(loss, feed_dict={\n",
    "        x_input: test.x,\n",
    "        y_input: test.y\n",
    "    })\n",
    "    print(f'TEST |{MSE:^4}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
